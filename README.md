ğŸ“° BERT News Classifier

An end-to-end Natural Language Processing (NLP) project that fine-tunes **BERT (Bidirectional Encoder Representations from Transformers)** for multi-class news classification and deploys it using a Flask web application.

This project demonstrates practical implementation of transformer-based models for real-world text classification tasks.

---

## ğŸ§  Project Overview

News articles are categorized into different topics such as:

- Politics
- Sports
- Business
- Technology
- Entertainment

This project uses a **fine-tuned BERT model** to automatically classify news headlines or content into their respective categories with high accuracy.

The system includes:

- Model training notebook
- Saved model artifacts (excluded from Git due to size)
- Label mapping
- Flask deployment app

---

## âœ¨ Key Features

- Fine-tuned BERT for text classification
- Multi-class prediction
- Confusion matrix evaluation
- Flask-based deployment
- Lightweight and clean repository
- Easy-to-extend architecture

---

## âš™ï¸ Tech Stack

- Python
- PyTorch
- Hugging Face Transformers
- Scikit-learn
- Flask
- Jupyter Notebook

---

## ğŸ“‚ Project Structure

BERT-News-Classifier/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ bert-news.ipynb
â”œâ”€â”€ label_mapping.json
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


> **Note:** Model files (`model.safetensors`) are not included due to GitHub size limits. See instructions below.

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/YOUR_USERNAME/BERT-News-Classifier.git
cd BERT-News-Classifier
2ï¸âƒ£ Create a virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Mac/Linux
3ï¸âƒ£ Install dependencies
pip install -r requirements.txt
4ï¸âƒ£ Run Flask App
python app.py
Open in your browser:

http://127.0.0.1:5000/
ğŸ“¥ Download Pre-trained Model
Due to GitHub file size limits, the model is not included.
Download the fine-tuned model here:

[Hugging Face / Google Drive Link]

Place the downloaded model in:

bert-news-classifier/
ğŸ§ª Example Input
The government announced new economic reforms today.
The football team secured a dramatic victory in the final minutes.
ğŸ“Š Model Details
Pretrained Model: bert-base-uncased

Fine-tuned for multi-class news classification

Optimizer: AdamW

Evaluation Metric: Accuracy & Confusion Matrix

ğŸš€ Future Improvements
Deploy on cloud (Render / AWS / Railway)

Add REST API endpoints

Add Docker support

Implement batch prediction

Improve UI design

ğŸ‘©â€ğŸ’» Author
AI/ML Enthusiast focused on building practical NLP applications using transformer-based models.
